{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uwjUFpsqZpWo"
      },
      "outputs": [],
      "source": [
        "# prompt: In the above animation, the rectangle sound only appears up to the respective degree. It should not overlap with the previous rectangle. and limitation on underfitting is 0 to 2.5 in width, good model is 2.5 to 5.5 in width, and for overfitting is 5.5 to 15. Give me the entire code once again.\n",
        "\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.linear_model import LinearRegression\n",
        "from sklearn.preprocessing import PolynomialFeatures\n",
        "from sklearn.metrics import mean_squared_error\n",
        "import matplotlib.animation as animation\n",
        "from sklearn.metrics import r2_score\n",
        "from matplotlib.patches import Rectangle\n",
        "import matplotlib.style as style\n",
        "\n",
        "style.use('dark_background')\n",
        "\n",
        "# Generate synthetic data\n",
        "np.random.seed(42)\n",
        "x_train = np.random.uniform(0, 10, 20)\n",
        "y_train = 2 + 0.5 * x_train**2 - 0.3 * x_train + np.random.normal(0, 4, len(x_train))\n",
        "\n",
        "x_test = np.random.uniform(0, 10, 20)\n",
        "y_test = 2 + 0.5 * x_test**2 - 0.3 * x_test + np.random.normal(0, 4, len(x_test))\n",
        "\n",
        "x_train = x_train[:, np.newaxis]\n",
        "x_test = x_test[:, np.newaxis]\n",
        "\n",
        "# Initialize figures and axes\n",
        "fig, (ax1, ax2, ax3) = plt.subplots(3, 1, figsize=(8, 15))\n",
        "x_range = np.linspace(0, 10, 200).reshape(-1, 1)\n",
        "\n",
        "# Plot for Polynomial Degree\n",
        "train_scatter1 = ax1.scatter(x_train, y_train, color=\"cyan\", label=\"Training Data\")\n",
        "test_scatter1 = ax1.scatter(x_test, y_test, color=\"lime\", label=\"Testing Data\")\n",
        "curve1, = ax1.plot([], [], color=\"red\", label=\"Model Curve\")\n",
        "ax1.legend()\n",
        "ax1.set_xlim(0, 10)\n",
        "ax1.set_ylim(0, 60)\n",
        "ax1.set_xlabel(\"Weight\")\n",
        "ax1.set_ylabel(\"Height\")\n",
        "\n",
        "# Plot for MSE\n",
        "train_errors = []\n",
        "test_errors = []\n",
        "line_train, = ax2.plot([], [], label=\"Training Error\", marker=\"o\", color=\"orange\")\n",
        "line_test, = ax2.plot([], [], label=\"Testing Error\", marker=\"o\", color=\"magenta\")\n",
        "ax2.set_xlabel(\"Polynomial Degree\")\n",
        "ax2.set_ylabel(\"Mean Squared Error\")\n",
        "ax2.set_title(\"Bias-Variance Tradeoff\")\n",
        "ax2.legend()\n",
        "ax2.set_xlim(0, 15)\n",
        "ax2.set_ylim(0, 50)\n",
        "\n",
        "# Plot for Adjusted R-squared\n",
        "adjusted_r2_values_train = []\n",
        "adjusted_r2_values_test = []\n",
        "line_adjusted_r2_train, = ax3.plot([], [], label=\"Training Adjusted R-squared\", marker=\"o\", color=\"purple\")\n",
        "line_adjusted_r2_test, = ax3.plot([], [], label=\"Testing Adjusted R-squared\", marker=\"o\", color=\"yellow\")\n",
        "ax3.set_xlabel(\"Polynomial Degree\")\n",
        "ax3.set_ylabel(\"Adjusted R-squared\")\n",
        "ax3.set_title(\"Model Performance\")\n",
        "ax3.legend()\n",
        "ax3.set_xlim(0, 15)\n",
        "ax3.set_ylim(0.6, 1)\n",
        "\n",
        "# Initialize rectangles\n",
        "rect1 = Rectangle((0, 0), 2.5, 1, alpha=0.3, color='red', label='Underfitting')\n",
        "rect2 = Rectangle((2.5, 0), 3, 1, alpha=0.3, color='green', label='Good Model')\n",
        "rect3 = Rectangle((5.5, 0), 9.5, 1, alpha=0.3, color='orange', label='Overfitting')\n",
        "ax3.add_patch(rect1)\n",
        "ax3.add_patch(rect2)\n",
        "ax3.add_patch(rect3)\n",
        "\n",
        "def update(degree):\n",
        "    global train_errors, test_errors, adjusted_r2_values_train, adjusted_r2_values_test, rect1, rect2, rect3\n",
        "    ax1.set_title(f\"Polynomial Degree: {degree}\")\n",
        "\n",
        "    poly = PolynomialFeatures(degree=degree)\n",
        "    x_poly_train = poly.fit_transform(x_train)\n",
        "    x_poly_test = poly.transform(x_test)\n",
        "    x_poly_range = poly.transform(x_range)\n",
        "\n",
        "    model = LinearRegression()\n",
        "    model.fit(x_poly_train, y_train)\n",
        "\n",
        "    y_pred_train = model.predict(x_poly_train)\n",
        "    y_pred_test = model.predict(x_poly_test)\n",
        "    y_pred_range = model.predict(x_poly_range)\n",
        "\n",
        "    train_error = mean_squared_error(y_train, y_pred_train)\n",
        "    test_error = mean_squared_error(y_test, y_pred_test)\n",
        "\n",
        "    train_errors.append(train_error)\n",
        "    test_errors.append(test_error)\n",
        "\n",
        "    curve1.set_data(x_range, y_pred_range)\n",
        "    line_train.set_data(range(1, len(train_errors) + 1), train_errors)\n",
        "    line_test.set_data(range(1, len(test_errors) + 1), test_errors)\n",
        "    ax2.relim()\n",
        "    ax2.autoscale_view()\n",
        "\n",
        "    n_train = len(y_train)\n",
        "    n_test = len(y_test)\n",
        "    p = degree\n",
        "    r2_train = r2_score(y_train, y_pred_train)\n",
        "    r2_test = r2_score(y_test, y_pred_test)\n",
        "    adjusted_r2_train = 1 - (1 - r2_train) * (n_train - 1) / (n_train - p - 1) if (n_train - p - 1) > 0 else np.nan\n",
        "    adjusted_r2_test = 1 - (1 - r2_test) * (n_test - 1) / (n_test - p - 1) if (n_test - p - 1) > 0 else np.nan\n",
        "\n",
        "    adjusted_r2_values_train.append(adjusted_r2_train)\n",
        "    adjusted_r2_values_test.append(adjusted_r2_test)\n",
        "\n",
        "    line_adjusted_r2_train.set_data(range(1, len(adjusted_r2_values_train) + 1), adjusted_r2_values_train)\n",
        "    line_adjusted_r2_test.set_data(range(1, len(adjusted_r2_values_test) + 1), adjusted_r2_values_test)\n",
        "    ax3.relim()\n",
        "    ax3.autoscale_view()\n",
        "\n",
        "    rect1.set_width(min(degree, 2.5))\n",
        "    rect2.set_width(min(max(0, degree - 2.5), 3))\n",
        "    rect3.set_width(min(max(0, degree-5.5), 9.5))\n",
        "\n",
        "    if degree == 1:\n",
        "        handles, labels = ax1.get_legend_handles_labels()\n",
        "        ax3.legend(handles + [rect1, rect2, rect3], labels + ['Underfitting', 'Good Model', 'Overfitting'])\n",
        "\n",
        "    return curve1, line_train, line_test, line_adjusted_r2_train, line_adjusted_r2_test, rect1, rect2, rect3\n",
        "\n",
        "ani = animation.FuncAnimation(fig, update, frames=range(1, 16), interval=1000, blit=False)\n",
        "ani.save(\"bias_variance_animation_dark.gif\", writer=\"pillow\")\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ]
    }
  ]
}